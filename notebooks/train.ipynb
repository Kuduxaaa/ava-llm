{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c84c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ñë‚ñë      ‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë‚ñë  ‚ñë‚ñë‚ñë      ‚ñë‚ñë\n",
      "‚ñí  ‚ñí‚ñí‚ñí‚ñí  ‚ñí‚ñí  ‚ñí‚ñí‚ñí‚ñí  ‚ñí‚ñí  ‚ñí‚ñí‚ñí‚ñí  ‚ñí\n",
      "‚ñì  ‚ñì‚ñì‚ñì‚ñì  ‚ñì‚ñì‚ñì  ‚ñì‚ñì  ‚ñì‚ñì‚ñì  ‚ñì‚ñì‚ñì‚ñì  ‚ñì\n",
      "‚ñà        ‚ñà‚ñà‚ñà‚ñà    ‚ñà‚ñà‚ñà‚ñà        ‚ñà\n",
      "‚ñà  ‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà‚ñà  ‚ñà‚ñà‚ñà‚ñà  ‚ñà\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import traceback\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from ava import AvaConfig, AvaForCausalLM\n",
    "from ava.data.datasets import AvaDataset\n",
    "from ava.training.trainer import train_model\n",
    "from ava.utils import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240dba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('notebooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5503a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AvaConfig().apply_for('100m')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6aa78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 50258\n",
      "Config vocabulary size: 50258\n"
     ]
    }
   ],
   "source": [
    "config.vocab_size = len(tokenizer)\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "config.bos_token_id = tokenizer.bos_token_id or tokenizer.eos_token_id\n",
    "config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(f'Tokenizer vocabulary size: {len(tokenizer)}')\n",
    "print(f'Config vocabulary size: {config.vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12f135",
   "metadata": {},
   "source": [
    "### Loading data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba84370",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/oasst1_english_conversations.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb62337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500/500 valid conversations\n"
     ]
    }
   ],
   "source": [
    "valid_data = []\n",
    "\n",
    "for conv in data:\n",
    "    if isinstance(conv, list) and len(conv) > 0:\n",
    "        valid_data.append(conv[0])\n",
    "\n",
    "print(f'Found {len(valid_data)}/{len(data)} valid conversations')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7a3eaa",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6cc2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(valid_data)\n",
    "split_idx = int(len(valid_data) * 0.9)\n",
    "train_data = valid_data[:split_idx]\n",
    "val_data = valid_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64437342",
   "metadata": {},
   "source": [
    "### Create datasets with fixed `max_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fcc847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 450\n",
      "Validation dataset size: 50\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 256\n",
    "train_dataset = AvaDataset(train_data, tokenizer, max_length=max_seq_length)\n",
    "val_dataset = AvaDataset(val_data, tokenizer, max_length=max_seq_length)\n",
    "\n",
    "print(f'Training dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f75a8",
   "metadata": {},
   "source": [
    "### Check for empty datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab214186",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "    raise ValueError('Dataset is empty after processing. Check data format and filtering.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67cd76",
   "metadata": {},
   "source": [
    "### Create dataloaders with small batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3cda5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle    = True,\n",
    "    collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size = batch_size,\n",
    "    collate_fn = collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec93795",
   "metadata": {},
   "source": [
    "### Check a sample batch to verify everything is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb5c47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch shapes:\n",
      "input_ids: torch.Size([2, 256])\n",
      "attention_mask: torch.Size([2, 256])\n",
      "labels: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_loader))\n",
    "\n",
    "print(f'Sample batch shapes:')\n",
    "print(f'input_ids: {sample_batch[\"input_ids\"].shape}')\n",
    "print(f'attention_mask: {sample_batch[\"attention_mask\"].shape}')\n",
    "print(f'labels: {sample_batch[\"labels\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a611b7d0",
   "metadata": {},
   "source": [
    "### Check maximum token ID in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d804394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum token ID in batch: 50257\n",
      "Tokenizer vocabulary size: 50258\n"
     ]
    }
   ],
   "source": [
    "max_token_id = torch.max(sample_batch['input_ids']).item()\n",
    "print(f'Maximum token ID in batch: {max_token_id}')\n",
    "print(f'Tokenizer vocabulary size: {len(tokenizer)}')\n",
    "\n",
    "if max_token_id >= len(tokenizer):\n",
    "    raise ValueError(f'Maximum token ID {max_token_id} is out of range for vocabulary size {len(tokenizer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43833467",
   "metadata": {},
   "source": [
    "### Initialize model with the updated config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142b1931",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AvaForCausalLM(config).to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr = 5e-5, \n",
    "    weight_decay = 0.01\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139dc2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_model(\n",
    "        model        = model,\n",
    "        train_loader = train_loader,\n",
    "        val_loader   = val_loader,\n",
    "        optimizer    = optimizer,\n",
    "        num_epochs   = 2,\n",
    "        device       = device\n",
    "    )\n",
    "    \n",
    "    torch.save(model.state_dict(), 'ava_model_trained.pt')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f'‚ùå Training error: {e}')\n",
    "    traceback.print_exc()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('üôÑ As you wish, Sir!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936146ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'User: What is AI?\\nAssistant:'\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
    "\n",
    "try:\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=100,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9\n",
    "    )\n",
    "    \n",
    "    print(tokenizer.decode(output[0]))\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Generation error: {e}')\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
